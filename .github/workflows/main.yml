name: Update Data

# Controls when the action will run. Triggers the workflow on push or pull request
# events but only for the master branch
on:  
  schedule:
    - cron: "15 5,6,11 * * *"
# TODO       
  push:
    branches: [ master ]


# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  job_0_clone_repo:
# Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
    runs-on: ubuntu-latest
    steps:
    - name: Checkout Repositiry
      uses: actions/checkout@v2

  job_0_setup_python:
    needs: [job_0_clone_repo]
    runs-on: ubuntu-latest
    steps:
    - name: Setup Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.8'
    
    - name: Cache Python pip
      uses: actions/cache@v2
      with:
        # This path is specific to Ubuntu
        path: ~/.cache/pip
        # Look to see if there is a cache hit for the corresponding requirements file
        key: ${{ runner.os }}-pip-${{ hashFiles('py-requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          ${{ runner.os }}-
    - name: Install dependencies
      run: pip install -r py-requirements.txt


  job_0_install_gnuplot:
    runs-on: ubuntu-latest
    steps:
    - name: Install Gnuplot
      run: |
        sudo apt-get update > /dev/null
        sudo apt-get install gnuplot > /dev/null


#  job_1_update_data:
#    needs: [job_0_clone_repo, job_0_setup_python]
#    runs-on: ubuntu-latest
#    steps:
## Fetch new data
#    - name: Run	fetch-de-divi
#      run: |
#        python3 fetch-de-divi-V2.py
#        python3 fetch-de-divi-V3.py
#
#    - name: Run fetch-de-states.py
#      run: python3 fetch-de-states-data.py
#      
#    - name: Run fetch-int-country-data.py
#      run: python3 fetch-int-country-data.py
#      
#    - name: Run fetch-de-districts.py
#      run: python3 fetch-de-districts.py
#      
#    - name: Run	show_data_dates.sh
#      run: bash show_data_dates.sh
#
#    - name: Commit new data files
#      run: |
#        git config --local user.email "action@github.com"
#        git config --local user.name "GitHub Action"
#        git add data/*
#        git diff-index --quiet HEAD || git commit -m "auto update"  | grep -v rewrite
#
#    - name: Push changes
#      uses: ad-m/github-push-action@master
#      with:
#        github_token: ${{ secrets.GITHUB_TOKEN }}
#        directory: data
#
#    - name: Zipping data
#      run: |
#        cd data
#        tar cfz ../cache/data.tgz *
#
#    - name: Upload data artifact via tip
#      uses: eine/tip@master
#      with:
#        token: ${{ secrets.GITHUB_TOKEN }}
#        files: |
#          cache/data.tgz

#  job_1_gnuplotting_data:
#    needs: [job_0_install_gnuplot,job_1_update_data]
#    runs-on: ubuntu-latest
#    steps:
## Gnuplot plotting
#    - name: Gnuplot plotting
#      run: |
#        cd scripts-gnuplot
#        gnuplot all.gp
#
#    - name: Zipping gnuplot plots
#      run: |
#        cd plots-gnuplot
#        tar cfz ../cache/plots-gnuplot.tgz *
#
#    - name: Upload data artifact via tip
#      uses: eine/tip@master
#      with:
#        token: ${{ secrets.GITHUB_TOKEN }}
#        files: |
#          cache/plots-gnuplot.tgz

# moved as a separate action, as it takes quite long
# Generate maps
#    - name: Generate + zip maps
#      run: | 
#        # sudo apt-get update > /dev/null
#        # sudo apt-get install imagemagick > /dev/null
#        python3 gen-map-de-districts.py
#        cd maps
#        tar cfz ../cache/maps.tgz *.gif

# Create pre-releases of tgz files


# not accessable anonymously
#    - name: Upload data artifact
#      uses: actions/upload-artifact@v1
#      with:
#        name: data
#        path: cache/data.tgz


# https://github.com/marketplace/actions/deploy-nightly
#    - name: Upload data artifact via deploy-nightly
#      uses: WebFreak001/deploy-nightly@v1.0.3
#      env:
#        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} # automatically provided by github actions
#      with:
#        upload_url: https://uploads.github.com/repos/entorb/COVID-19-Coronavirus-German-Regions/releases/27395320/assets{?name,label} 
## find out this value by opening https://api.github.com/repos/<owner>/<repo>/releases in your browser and copy the full "upload_url" value including the {?name,label} part
#        release_id: 27395320 # same as above (id can just be taken out the upload_url, it's used to find old releases)
#        asset_path: cache/data.tgz # path to archive to upload
#        asset_name: data.tgz # name to upload the release as, use $$ to insert date (YYYYMMDD) and 6 letter commit hash
#        asset_content_type: application/tgz # required by GitHub API
##        max_releases: 7 # optional, if there are more releases than this matching the asset_name, the oldest ones are going to be deleted      



